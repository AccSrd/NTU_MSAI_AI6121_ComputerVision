{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35126d7d",
   "metadata": {},
   "source": [
    "## CV Project: ResNet-18\n",
    "@author: Hantao Li\n",
    "\n",
    "This code file constructs the ResNet-18 model and uses it to carry out relevant experiments of the MNIST dataset.\n",
    "This code refers to the code of the official ResNet of PyTorch [1] and the example code given by Prof. Boyang Li in the AI 6103 course.\n",
    "Since the main part of this experiment is the construction of MLP network, CNN is only used as improvement, where coding is not the main task; therefore, the repeatability with the two reference codes is Relatively high.\n",
    "\n",
    "\n",
    "[1] https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5386b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae77d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, net, criterion, trainloader, scheduler):\n",
    "    device = 'cuda'\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        if (batch_idx+1) % 50 == 0:\n",
    "          print(\"iteration : %3d, loss : %0.4f, accuracy : %2.2f\" % (batch_idx+1, train_loss/(batch_idx+1), 100.*correct/total))\n",
    "\n",
    "    scheduler.step()\n",
    "    return train_loss/(batch_idx+1), 100.*correct/total\n",
    "\n",
    "def test(epoch, net, criterion, testloader):\n",
    "    device = 'cuda'\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.inference_mode():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    return test_loss/(batch_idx+1), 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7847f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        # This is the \"stem\"\n",
    "        # For CIFAR (32x32 images), it does not perform downsampling\n",
    "        # It should downsample for ImageNet\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        # four stages with three downsampling\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e45f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.02, 3.3), value=(0))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=256, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcb59c0",
   "metadata": {},
   "source": [
    "### Basic Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36ce173",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# main body\n",
    "\n",
    "loopnumber = 1\n",
    "epochnumber = 300\n",
    "task_name = 'lr001_wd00005_cos_random_noflip'\n",
    "\n",
    "train_loss_all = []\n",
    "train_acc_all = []\n",
    "test_loss_all = []\n",
    "test_acc_all = []\n",
    "\n",
    "for loop in range(1,loopnumber+1):\n",
    "    \n",
    "    config = {\n",
    "    'lr': 0.01,\n",
    "    'momentum': 0.9,\n",
    "    'weight_decay': 0.0005\n",
    "    }\n",
    "\n",
    "    net = ResNet18().to('cuda')\n",
    "    criterion = nn.CrossEntropyLoss().to('cuda')\n",
    "    optimizer = optim.SGD(net.parameters(), lr=config['lr'],\n",
    "                          momentum=config['momentum'], weight_decay=config['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochnumber)\n",
    "    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, epochnumber, gamma=1, last_epoch=-1)\n",
    "    \n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "    \n",
    "    print(\"###### The \"+str(loop)+\" Loop Starting...\")\n",
    "    for epoch in range(1, epochnumber+1):\n",
    "        train_loss_cur, train_acc_cur = train(epoch, net, criterion, trainloader, scheduler)\n",
    "        test_loss_cur, test_acc_cur = test(epoch, net, criterion, testloader)\n",
    "\n",
    "        print((\"Epoch : %3d, training loss : %0.4f, training accuracy : %2.2f, test loss \" + \\\n",
    "          \": %0.4f, test accuracy : %2.2f\") % (epoch, train_loss_cur, train_acc_cur, test_loss_cur, test_acc_cur))\n",
    "\n",
    "        train_loss.append(train_loss_cur)\n",
    "        test_loss.append(test_loss_cur)\n",
    "        train_acc.append(train_acc_cur)\n",
    "        test_acc.append(test_acc_cur)\n",
    "        \n",
    "    train_loss_all.append(train_loss)\n",
    "    test_loss_all.append(test_loss)\n",
    "    train_acc_all.append(train_acc)\n",
    "    test_acc_all.append(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8470e117",
   "metadata": {},
   "source": [
    "### Plot Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acabedf5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Draw the curve of episodes vs. rewards\n",
    "train_loss_x = np.vstack((train_loss_all[0], train_loss_all[1]))\n",
    "for i in range(2, loopnumber):\n",
    "    train_loss_x = np.vstack((train_loss_x, train_loss_all[i]))\n",
    "    \n",
    "test_loss_x = np.vstack((test_loss_all[0], test_loss_all[1]))\n",
    "for i in range(2, loopnumber):\n",
    "    test_loss_x = np.vstack((test_loss_x, test_loss_all[i]))\n",
    "\n",
    "df1 = pd.DataFrame(train_loss_x).melt(var_name='Epochs',value_name='Loss')\n",
    "df2 = pd.DataFrame(test_loss_x).melt(var_name='Epochs',value_name='Loss')\n",
    "\n",
    "plt.figure(dpi=600)\n",
    "sns.lineplot(x=\"Epochs\", y=\"Loss\", data=df1)\n",
    "sns.lineplot(x=\"Epochs\", y=\"Loss\", data=df2)\n",
    "\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Number of epochs\")\n",
    "plt.legend(['train', 'test'])\n",
    "\n",
    "plt.savefig(\"./Output/\"+task_name+\"_loss.png\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "train_acc_x = np.vstack((train_acc_all[0], train_acc_all[1]))\n",
    "for i in range(2, loopnumber):\n",
    "    train_acc_x = np.vstack((train_acc_x, train_acc_all[i]))\n",
    "    \n",
    "test_acc_x = np.vstack((test_acc_all[0], test_acc_all[1]))\n",
    "for i in range(2, loopnumber):\n",
    "    test_acc_x = np.vstack((test_acc_x, test_acc_all[i]))\n",
    "\n",
    "df3 = pd.DataFrame(train_acc_x).melt(var_name='Epochs',value_name='Accuracy')\n",
    "df4 = pd.DataFrame(test_acc_x).melt(var_name='Epochs',value_name='Accuracy')\n",
    "\n",
    "plt.figure(dpi=600)\n",
    "sns.lineplot(x=\"Epochs\", y=\"Accuracy\", data=df3)\n",
    "sns.lineplot(x=\"Epochs\", y=\"Accuracy\", data=df4)\n",
    "\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy vs Number of epochs\")\n",
    "plt.legend(['train', 'test'])\n",
    "\n",
    "plt.savefig(\"./Output/\"+task_name+\"_acc.png\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f830f5",
   "metadata": {},
   "source": [
    "### Calculate Average Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d7cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_train_acc = sum(train_acc_x[:,14])/loopnumber\n",
    "average_test_acc = sum(test_acc_x[:,14])/loopnumber\n",
    "average_train_loss = sum(train_loss_x[:,14])/loopnumber\n",
    "average_test_loss = sum(test_loss_x[:,14])/loopnumber\n",
    "\n",
    "print((\"training loss : %0.4f, training accuracy : %2.2f, test loss \" + \\\n",
    "          \": %0.4f, test accuracy : %2.2f\") % (average_train_loss, average_train_acc, average_test_loss, average_test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7584244",
   "metadata": {},
   "source": [
    "### Plot Curves for single epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2673d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=600)\n",
    "plt.plot(range(len(train_loss)), train_loss, 'b')\n",
    "plt.plot(range(len(test_loss)), test_loss, 'r')\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Number of epochs\")\n",
    "plt.legend(['train', 'test'])\n",
    "plt.savefig(\"./Output/\"+task_name+\"_loss.png\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(dpi=600)\n",
    "plt.plot(range(len(train_acc)), train_acc, 'b')\n",
    "plt.plot(range(len(test_acc)), test_acc, 'r')\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy vs Number of epochs\")\n",
    "plt.legend(['train', 'test'])\n",
    "plt.savefig(\"./Output/\"+task_name+\"_acc.png\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b5f7e9",
   "metadata": {},
   "source": [
    "If we want to use the torchvision.models.resnet18, we should reformatt the image first, \n",
    "which means that [128, 1, 28, 28] -> [64, 3, 7, 7]. We need to do a convolution first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94af924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "model = torchvision.models.resnet18() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch]",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
